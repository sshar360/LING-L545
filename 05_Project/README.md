# Tri-Lingual Sign Language Translator

`Sign language is mostly utilized by
hearing-impaired and mute people to communicate within and outside of their social groups. The goal of sign-language
recognition(SLR)[1], is to identify acquired hand motions and to continue until
related hand gestures are translated. The
fact that some or all of the ordinary people do not speak this language and that every country has its sign language creates a
barrier to communication. I have created a
model that can understand the gestures and
translate them to cater to a wider audience.
By developing Deep Neural Network[2]
architectures, the model will learn to detect letters and once the model successfully recognizes[3] the gesture, a relevant
letter is generated. This paper will be a
two-fold endeavor with comparative study
as the research part and Tri-Lingual sign
language translator, as the application part.`
